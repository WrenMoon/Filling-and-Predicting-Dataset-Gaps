import pandas as pd
import numpy as np
from numpy import float32
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_percentage_error

# Load data
TodasEstaciones = pd.read_csv('Data/Chlor_A data.csv', index_col=0, parse_dates=True)
dates = pd.read_csv('Data/Dates.csv')

# Set date range for data
start_date = dates.loc[0, 'start_date']
end_date = dates.loc[0, 'end_date']

# Training dates
training_start = dates.loc[0, 'start_date']
training_end = dates.loc[0, 'gap_start']

# Define station columns
Est1 = 'Est1'
Est2 = 'Est2'
Est3 = 'Est3'

# Add a week column
TodasEstaciones['date'] = TodasEstaciones.index
TodasEstaciones['week'] = TodasEstaciones['date'].apply(lambda x: x.isocalendar()[1])
del TodasEstaciones['date']

# Define training sets
X_train = TodasEstaciones.loc[training_start:training_end, [Est1, Est3, 'week']].astype(float32).values
y_train = TodasEstaciones.loc[training_start:training_end, Est2].astype(float32).values

# Scale training data
scaler = StandardScaler().fit(X_train)
X_train = scaler.transform(X_train)

# Build and train model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(300, activation='linear', input_shape=(3,)),
    Dense(700, activation='linear'),
    Dense(200, activation='linear'),
    Dense(50, activation='linear'),
    Dense(1, activation='linear')
])
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=1000, verbose=2)

# Predict for the whole date range
X_missing = TodasEstaciones.loc[start_date:end_date, [Est1, Est3, 'week']].astype(float32).values
X_missing = scaler.transform(X_missing)
y_missing = model.predict(X_missing)

# Create a new column for completed Est2 predictions
TodasEstaciones['Est2_Completed'] = TodasEstaciones[Est2]
TodasEstaciones.loc[start_date:end_date, 'Est2_Completed'] = y_missing

# Ensure no NaNs in y_true and y_pred for MAPE calculation
y_true = TodasEstaciones.loc[training_end:end_date, Est2].values  # Only true values after training
y_pred = TodasEstaciones.loc[training_end:end_date, 'Est2_Completed'].values.flatten()  # Predictions

# Filter out NaNs from both y_true and y_pred
mask = ~np.isnan(y_true) & ~np.isnan(y_pred)
y_true_filtered = y_true[mask]
y_pred_filtered = y_pred[mask]

# Calculate MAPE on filtered data
if len(y_true_filtered) > 0 and len(y_pred_filtered) > 0:
    mape = mean_absolute_percentage_error(y_true_filtered, y_pred_filtered)
else:
    mape = None

# Add predictions and MAPE to filled DataFrame
filled_df = pd.read_csv('Data/Filled_Chlorophyll_Data.csv', index_col=0, parse_dates=True)
filled_df['Neural Network Prediction'] = TodasEstaciones['Est2_Completed']

# Save updated filled values with predictions to a new CSV file
filled_df.to_csv('Data/Filled_Chlorophyll_Data.csv')

# Print MAPE result
if mape is not None:
    print(f"MAPE for the predictions: {mape * 100:.2f}%")
else:
    print("No valid data for MAPE calculation.")
